{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no image with label 0 so name is empty\n",
    "subjects = [\"\",\"Roy\",\"Samuels\",\"Ethan\",\"John\",\"Draxi\",\"Maxi\",\"Tyson\",\"Claire\",\"Ray\",\"Yuri\",\"chin\",\"Nina\",\"Kazayu\",\"Jin\",\"Eddy\",\"DR.B\",\"Drax\",\"Peter\",\"Kick\",\"Gunther\",\"Billy\",\"Leo\",\"Ralph\",\"Mikelangelo\",\"Doni\",\"Aadi\",\"Abhi\",\"Piyush\",\"Harshit\",\"Goku\",\"gohan\",\"Anushka\",\"Brian\",\"Howrang\",\"Anna\",\"Aman\",\"Kartik\",\"Prashant\",\"Lakshay\",\"Puneet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(image):\n",
    "    gray_images = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier('/home/tushar/opencv/data/lbpcascades/lbpcascade_frontalface.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray_images, scaleFactor=1.2, minNeighbors=5);\n",
    "    \n",
    "    \n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    \n",
    "    (x, y, w, h) = faces[0]\n",
    "    \n",
    "    \n",
    "    return gray_images[y:y+w, x:x+h], faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_trainingData(data_folder_path):\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    faces = []\n",
    "    labels = []\n",
    "    for dir_name in dirs:\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue;\n",
    "        label = int(dir_name.replace(\"s\",\"\"))\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        for image_name in subject_images_names:\n",
    "            if image_name.startswith(\".\"):\n",
    "                continue;\n",
    "            image_path = subject_dir_path + \"/\" + image_name\n",
    "            image = cv2.imread(image_path)\n",
    "            cv2.imshow(\"Training on image...\", cv2.resize(image, (400, 500)))\n",
    "            cv2.waitKey(100)\n",
    "            face, rect = detect_faces(image)\n",
    "            if face is not None:\n",
    "            \n",
    "                faces.append(face)\n",
    "                \n",
    "                labels.append(label)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return faces, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total faces: 265\n",
      "total labels: 265\n"
     ]
    }
   ],
   "source": [
    "faces, labels = prepare_trainingData('/home/tushar/Documents/Face Recognition/orl_faces')\n",
    "print(\"total faces:\", len(faces))\n",
    "print(\"total labels:\", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training face recognizer\n",
    "face_recognizer = cv2.face.createLBPHFaceRecognizer()\n",
    "face_recognizer.train(faces, np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(img,rect):\n",
    "    (x, y, w, h) = rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    \n",
    "def draw_text(img, text, x, y):\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_image):\n",
    "    img = test_image.copy()\n",
    "    face, rect = detect_faces(img)\n",
    "    labels = face_recognizer.predict(img)\n",
    "    labesl_text = subjects[labels]\n",
    "    draw_rectangle(img, rect)\n",
    "    draw_text(img, label_text, rect[0], rect[1]-5)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting images...\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/home/travis/miniconda/conda-bld/conda_1486587069159/work/opencv-3.1.0/build/opencv_contrib/modules/face/src/lbph_faces.cpp:247: error: (-213) Using Original Local Binary Patterns for feature extraction only works on single-channel images (given 16). Please pass the image data as a grayscale image! in function elbp\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0fee91de385e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#perform a prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpredicted_img1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mpredicted_img2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-37348c786a73>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(test_image)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlabesl_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubjects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdraw_rectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /home/travis/miniconda/conda-bld/conda_1486587069159/work/opencv-3.1.0/build/opencv_contrib/modules/face/src/lbph_faces.cpp:247: error: (-213) Using Original Local Binary Patterns for feature extraction only works on single-channel images (given 16). Please pass the image data as a grayscale image! in function elbp\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting images...\")\n",
    "\n",
    "#load test images\n",
    "test_img1 = cv2.imread(\"/home/tushar/Documents/Face Recognition/Test images/2.jpg\")\n",
    "test_img2 = cv2.imread(\"/home/tushar/Documents/Face Recognition/Test images/9.jpg\")\n",
    "\n",
    "#perform a prediction\n",
    "predicted_img1 = predict(test_img1)\n",
    "predicted_img2 = predict(test_img2)\n",
    "print(\"Prediction complete\")\n",
    "\n",
    "#display both images\n",
    "cv2.imshow(subjects[1], predicted_img1)\n",
    "cv2.imshow(subjects[2], predicted_img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
